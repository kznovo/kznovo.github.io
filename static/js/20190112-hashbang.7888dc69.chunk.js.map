{"version":3,"sources":["components/blog/20190112/index.js"],"names":["Post20190112","document","title","this","props","react__WEBPACK_IMPORTED_MODULE_5___default","a","createElement","Fragment","date","react_highlight__WEBPACK_IMPORTED_MODULE_6___default","className","href","target","rel","React","Component"],"mappings":"+MAIqBA,qMAEjBC,SAASC,MAAQ,YAAcC,KAAKC,MAAMF,uCAI1C,OACJG,EAAAC,EAAAC,cAAAF,EAAAC,EAAAE,SAAA,KACAH,EAAAC,EAAAC,cAAA,UAAKJ,KAAKC,MAAMF,OAChBG,EAAAC,EAAAC,cAAA,aAAQJ,KAAKC,MAAMK,MACnBJ,EAAAC,EAAAC,cAAA,WAEAF,EAAAC,EAAAC,cAAA,sbAIAF,EAAAC,EAAAC,cAAA,iCACAF,EAAAC,EAAAC,cAAA,sCAGAF,EAAAC,EAAAC,cAACG,EAAAJ,EAAD,CAAWK,UAAU,QAArB,+EACAN,EAAAC,EAAAC,cAAA,iBACOF,EAAAC,EAAAC,cAAA,oBADP,oBAC2CF,EAAAC,EAAAC,cAAA,0BAD3C,qCACsGF,EAAAC,EAAAC,cAAA,yBADtG,MAGAF,EAAAC,EAAAC,cAAA,SACEF,EAAAC,EAAAC,cAAA,0BADF,wDACgFF,EAAAC,EAAAC,cAAA,wBADhF,0HAGAF,EAAAC,EAAAC,cAAA,UACEF,EAAAC,EAAAC,cAAA,mFAEEF,EAAAC,EAAAC,cAACG,EAAAJ,EAAD,CAAWK,UAAU,QAArB,8EAFF,gEAG+DN,EAAAC,EAAAC,cAAA,kDAH/D,qCAG6IF,EAAAC,EAAAC,cAAA,iDAH7I,+IAGoUF,EAAAC,EAAAC,cAAA,wBAHpU,KAKAF,EAAAC,EAAAC,cAAA,wIAC6HF,EAAAC,EAAAC,cAAA,oCAD7H,4HACyRF,EAAAC,EAAAC,cAAA,qCADzR,MAIFF,EAAAC,EAAAC,cAAA,sBACYF,EAAAC,EAAAC,cAAA,0BADZ,yLAC2NF,EAAAC,EAAAC,cAAA,KAAGK,KAAK,oFAAoFC,OAAO,SAASC,IAAI,uBAAhH,mCAD3N,icACk0BT,EAAAC,EAAAC,cAAA,KAAGK,KAAK,wFAAwFC,OAAO,SAASC,IAAI,uBAApH,iDADl0B,cACwgCT,EAAAC,EAAAC,cAAA,KAAGK,KAAK,sFAAsFC,OAAO,SAASC,IAAI,uBAAlH,6EADxgC,kIAC41CT,EAAAC,EAAAC,cAAA,KAAGK,KAAK,+DAA+DC,OAAO,SAASC,IAAI,uBAA3F,qBAD51C,sCAIAT,EAAAC,EAAAC,cAAA,oCAGAF,EAAAC,EAAAC,cAAA,wSAGAF,EAAAC,EAAAC,cAAA,iSAGAF,EAAAC,EAAAC,cAACG,EAAAJ,EAAD,CAAWK,UAAU,QAArB,4EACAN,EAAAC,EAAAC,cAAA,wDAC8CF,EAAAC,EAAAC,cAAA,6DAD9C,4QAGAF,EAAAC,EAAAC,cAAA,wxBAC8wBF,EAAAC,EAAAC,cAAA,KAAGK,KAAK,qEAAqEC,OAAO,SAASC,IAAI,uBAAjG,kGAD9wB,aAGAT,EAAAC,EAAAC,cAAA,iGACuFF,EAAAC,EAAAC,cAAA,KAAGK,KAAK,+EAA+EC,OAAO,SAASC,IAAI,uBAA3G,mGADvF,2iBAIAT,EAAAC,EAAAC,cAAA,0CACAF,EAAAC,EAAAC,cAAA,4CACkCF,EAAAC,EAAAC,cAAA,KAAGK,KAAK,sFAAsFC,OAAO,SAASC,IAAI,uBAAlH,oBADlC,oGAC+RT,EAAAC,EAAAC,cAAA,cAAQF,EAAAC,EAAAC,cAAA,KAAGK,KAAK,+DAA+DC,OAAO,SAASC,IAAI,uBAA3F,kBADvS,OACsbT,EAAAC,EAAAC,cAAA,cAAQF,EAAAC,EAAAC,cAAA,KAAGK,KAAK,4DAA4DC,OAAO,SAASC,IAAI,uBAAxF,eAD9b,4BAC4lBT,EAAAC,EAAAC,cAAA,cAAQF,EAAAC,EAAAC,cAAA,KAAGK,KAAK,4EAA4EC,OAAO,SAASC,IAAI,uBAAxG,aADpmB,oCACwxBT,EAAAC,EAAAC,cAAA,qBADxxB,qEAIAF,EAAAC,EAAAC,cAACG,EAAAJ,EAAD,CAAWK,UAAU,cAArB,sjBA2BAN,EAAAC,EAAAC,cAAA,oCAIAF,EAAAC,EAAAC,cAAA,qWAIAF,EAAAC,EAAAC,cAAA,iCACsBF,EAAAC,EAAAC,cAAA,KAAGK,KAAK,6DAA6DC,OAAO,SAASC,IAAI,uBAAzF,wCADtB,2BAGAT,EAAAC,EAAAC,cAAA,uQAC6PF,EAAAC,EAAAC,cAAA,KAAGK,KAAK,6CAA6CC,OAAO,SAASC,IAAI,uBAAzE,UAD7P,aAxG0CC,IAAMC","file":"static/js/20190112-hashbang.7888dc69.chunk.js","sourcesContent":["import React from \"react\";\nimport Highlight from \"react-highlight\";\nimport \"../Blog.css\";\n\nexport default class Post20190112 extends React.Component {\n  componentDidMount() {\n    document.title = \"Kznovo - \" + this.props.title;\n  }\n\n  render() {\n    return (\n<>\n<h2>{this.props.title}</h2>\n<small>{this.props.date}</small>\n<br/>\n\n<p>\n  This post will be useful for people who wants to setup an SPA on GitHub Pages and wants to know how to handle client-side routing while taking control of the SEO. Hashbang routing may be a bit of 2010-ish tech. But the justification of this tech's usage comes from the fact that Google recently changed their stance towards ajax-based webpage crawling for their search engine, and IMHO it is actually quite new! You'll see...\n</p>\n\n<h3>What is a hashbang?</h3>\n<p>\n  See the url of this post:\n</p>\n<Highlight className=\"HTTP\">https://kznovo.github.io/#!/blog/2019/01/13/blog-project-2-hashbang-routing</Highlight>\n<p>\n  The \"<strong>#!</strong>\" part is called <strong>hashbang</strong>. It is sometimes abbreviated as \"<strong>shebang</strong>\".\n</p>\n<p>\n  <strong>Hash (#)</strong> inside URL enforces browser to use only the strings <strong>before</strong> the syntax upon making any HTTP request to the server. It is typically used for either one of the following purposes:\n</p>\n<ul>\n  <li>\n    To jump sections within an HTML. For example, this wikipedia page URL:\n    <Highlight className=\"HTTP\">https://en.wikipedia.org/wiki/Unicorn#Similar_animals_in_religion_and_myth</Highlight>\n    If you access it, your browser only sends an HTTP request to <i>https://en.wikipedia.org/wiki/Unicorn</i>. Then the string after the hash (<i>Similar_animals_in_religion_and_myth</i>) is used to move the view of the content to that section after the page is loaded to the browser. This usage of hash is usually called the <strong>anchor</strong>.\n  </li>\n  <li>\n    The string after the hash is used by the Javascript code to render contents dynamically inside the browser. This is called <strong>Ajax-based webpage</strong>, and when this behavior is used to mimic page transition by re-rendering most of the contents on the page, it is called <strong>client-side routing</strong>.\n  </li>\n</ul>\n<p>\n  Used with <strong>bang (!)</strong>, the syntax becomes hashbang, which instructs Google's spider robots, aka Googlebots, to index the contents of the page for their search engine on the full path. This technique was <a href=\"https://webmasters.googleblog.com/2009/10/proposal-for-making-ajax-crawlable.html\" target=\"_blank\" rel=\"noopener noreferrer\">proposed by Google back in 2009</a> when Ajax-based webpages was becoming a thing, and back then the web developers would prepare a static HTML called \"HTML snapshot\" for the Googlebots to crawl. Many websites such as Twitter and Facebook started to adopt this practice, but eventually stopped because of the criticism around performance deterioration, code bug vulnerability, and ugly URL. The criticism really sparked around 2012 when the large American gossip news media Gawker <a href=\"https://www.wired.com/2011/02/gawker-learns-the-hard-way-why-hash-bang-urls-are-evil/\" target=\"_blank\" rel=\"noopener noreferrer\">adopted hashbang and broke its entire website</a>. In 2015, <a href=\"https://webmasters.googleblog.com/2015/10/deprecating-our-ajax-crawling-scheme.html\" target=\"_blank\" rel=\"noopener noreferrer\">Google officially deprecated the ajax-crawling scheme it proposed in 2009</a>. Today, it is generally considered a bad excersise to use hashbang for routing. Instead, the web community suggests using the <a href=\"https://developer.mozilla.org/en-US/docs/Web/API/History_API\" target=\"_blank\" rel=\"noopener noreferrer\">HTML5 history api</a> to handle dynamic page rendering.\n</p>\n\n<h3>\n  Then why use hashbang?\n</h3>\n<p>\n  Because this blog is dynamically rendered SPA (single page application), and hashbang is the only sensible way to take care of both the routing and the SEO on GitHub Pages. And although I mentioned it has been abandoned by Google before, it got its support back from Google recently.\n</p>\n<p>\n  Since this blog is an SPA written in React, I need all the requests coming into this website to fetch the root index.html file that holds the Javascript first, otherwise nothing would render properly. GitHub Pages throws 404 not found error response if my URL looks like this:\n</p>\n<Highlight className=\"HTTP\">https://kznovo.github.io/blog/2019/01/13/blog-project-2-hashbang-routing</Highlight>\n<p>\n  The browser tries to fetch resources at the <i>/blog/2019/01/13/blog-project-2-hashbang-routing</i> endpoint, where there is no resource exposed. Instead, by having the hashbang sit right after the root url, the subsequent parameters are ignored at request, but once index.html is loaded, the contents are rendered dynamically based on the full path's parameters.\n</p>\n<p>\n  GitHub Pages actually presents two options to bypass the client-side routing issue, and one of the options is to use the hash-based routing discussed above. The other option is to use the custom GitHub Pages 404 fallback feature, which I chose not to use. GitHub Pages enables users to use their own HTML file to be rendered whenever the server issues a 404 response. Users could either render the dynamic contents on this file itself by copying the same HTML/CSS/Javascript as the root HTML file, or issue a redirect to the root HTML file and keep on rendering there. This is a hacky workaround, and it involves an inevitable 404 response which I did not like. It also messes up the SEO as Googlebots would consider the 404 response as an error and do not index the page at all. <a href=\"https://github.com/isaacs/github/issues/408#issuecomment-392296363\" target=\"_blank\" rel=\"noopener noreferrer\">Same kind of issue seems to happen on Twitter's Card Validator and Facebook's Sharing Debugger</a> as well.\n</p>\n<p>\n  Despite all the criticisms towards hashbangs as I discussed in the previous section, <a href=\"https://webmasters.googleblog.com/2017/12/rendering-ajax-crawling-pages.html\" target=\"_blank\" rel=\"noopener noreferrer\">Google officially resumed supporting hashbang crawling starting from the second quarter of 2018</a>, so the search engine support issue is kind of gone now. There's even a slight upgrade from the previous ajax-crawling scheme, that now Googlebots can execute the javascript themselves to take the snapshot of the webpage, thus there's no need to create the \"HTML snapshot\" anymore. It is still true that the URL looks ugly and a single typo in my Javascript would screw up my entire website. However, compared to the another hacky option, this route presents more merits than the other, such as the SEO support and no mandatory 404 error responses.\n</p>\n\n<h3>Implementing hashbang routes</h3>\n<p>\n  This was easy as I am using the <a href=\"https://github.com/ReactTraining/react-router/tree/master/packages/react-router-dom\" target=\"_blank\" rel=\"noopener noreferrer\">react-router-dom</a> npm package that supports it out of the box. All I had to do was to swap the router object from <strong><a href=\"https://reacttraining.com/react-router/web/api/BrowserRouter\" target=\"_blank\" rel=\"noopener noreferrer\">BrowserRouter</a></strong> to <strong><a href=\"https://reacttraining.com/react-router/web/api/HashRouter\" target=\"_blank\" rel=\"noopener noreferrer\">HashRouter</a></strong>. Also, HashRouter takes <strong><a href=\"https://reacttraining.com/react-router/web/api/HashRouter/hashtype-string\" target=\"_blank\" rel=\"noopener noreferrer\">hashType</a></strong> argument in which I can specify <i>hashbang</i> as the type of hash to use. The below is the simplified example:\n</p>\n\n<Highlight className=\"javascript\">{`\nimport React from \"react\";\nimport ReactDOM from 'react-dom';\nimport { HashRouter as Router, Route, Switch } from \"react-router-dom\";\n\n\nconst Home = () => <p>Home Page!</p>;\n\nconst About = () => <p>About Page!</p>;\n\n\nclass App extends React.Component {\n  render() {\n    return(\n      <Router hashType=\"hashbang\">\n        <Switch>\n          <Route exact path=\"/\" component={Home}>\n          <Route exact path=\"/\" component={About}>\n        </Switch>\n      <Router>\n    );\n  }\n}\n\nReactDOM.render(<App/>, documnt.getElementById(\"root\"));\n`}</Highlight>\n\n<p>\n  Nothing very technical.\n</p>\n\n<p>\n  Now, if I am managing my own file server for this website, I'd use the HTML5 history pushState api. This can be achieved by configuring the server to forcefully use the root index HTML file everytime there's a request, and each server has its own way of implementing this, but GitHub Pages does not present the users with this option as of now.\n</p>\n\n<h3>\n  What happens to the <a href=\"https://twitter.com/KazuyaHatta/status/1081464142710505472\" target=\"_blank\" rel=\"noopener noreferrer\">tweet I made about the previous post</a> using a different URL?\n</h3>\n<p>\n  For now, there is nothing I can do about it. This is something that bugs me. What if GitHub Pages starts to support client-side routing and opens up their server configurations? That would be cool, but am I going to change the URL again? That will be <a href=\"https://www.w3.org/Provider/Style/URI.html\" target=\"_blank\" rel=\"noopener noreferrer\">uncool</a>.\n</p>\n</>\n\n    );\n  }\n}\n"],"sourceRoot":""}